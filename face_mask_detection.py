# -*- coding: utf-8 -*-
"""face_mask_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e_u5Se90N88NafH3FVN1zLHHxQfjAEEk
"""

# Unzipping face mask image dataset
!unzip /content/drive/MyDrive/face-mask-dataset_new.zip

from keras.optimizers import RMSprop,Adam
from keras.preprocessing.image import ImageDataGenerator
import cv2
from keras.models import Sequential
from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout
from keras.models import Model, load_model
from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from sklearn.utils import shuffle
import imutils
import numpy as np
import tensorflow as tf
import keras

# training directory

TRAINING_DIR = "/content/face-mask-dataset_new/dataset_new/train"
train_datagen = ImageDataGenerator(rescale=1.0/255,
                                   rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

train_generator = train_datagen.flow_from_directory(TRAINING_DIR, 
                                                    batch_size=10,
                                                    target_size=(64, 64))

# Validation directory

VALIDATION_DIR = "/content/face-mask-dataset_new/dataset_new/test"
validation_datagen = ImageDataGenerator(rescale=1.0/255,
                                  rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, 
                                                         batch_size=10, 
                                                         target_size=(64, 64))

# creating model and adding layers to it

model =Sequential([
    Conv2D(128, (5,5), activation='relu', input_shape=(64,64,3)),
    Conv2D(64, (5,5), activation='relu'),
    MaxPooling2D(2,2),
    
    Conv2D(16, (3,3), activation='relu'),
    Conv2D(4, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    
    Flatten(),
    Dropout(0.5),
    Dense(1024, activation='relu'),
    Dense(512, activation='relu'),
    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(2, activation='softmax')
])

# compiling the model 
model.compile(optimizer=Adam(learning_rate=0.000001), loss='binary_crossentropy', metrics=['acc'])

# creating path to save/load model
filepath="/content/drive/MyDrive/mask_detect_model_last.hdf5"

# creating callbacks for earlystoping and to save model only when val_loss decreases
 keras_callbacks=[

                EarlyStopping(
                monitor='val_loss', 
                patience=15, 
                mode='min',
                min_delta=0.0001),

                ModelCheckpoint(
                    filepath,
                    monitor='val_loss',
                    verbose=1,
                    save_best_only=True,
                    mode='auto')
]

# training the model
history = model.fit(train_generator,
                              epochs=50,
                              validation_data=validation_generator,
                              callbacks=keras_callbacks)





# load the to retrain again from last epoch
from keras.saving.hdf5_format import load_model_from_hdf5

model=load_model_from_hdf5(filepath, custom_objects=None, compile=True)
history = model.fit(train_generator,
                              epochs=20,
                              validation_data=validation_generator,
                              callbacks=keras_callbacks)



print(keras.__version__)

